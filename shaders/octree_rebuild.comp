/* ---------------------------------------------------------------- *\
 * octree_rebuild.comp
 * Author: Gavin Ralston
 * Date Created: 2025-03-08
\* ---------------------------------------------------------------- */
#version 460

#define WORKGROUP_SIZE 2

#define PI 3.14

layout (local_size_x = WORKGROUP_SIZE, local_size_y = WORKGROUP_SIZE, local_size_z = WORKGROUP_SIZE) in;

struct OctreeNode
{
	uint indirection;
	uint voxel_type;
};

layout (std430, binding = 0) buffer octree_ssbo
{
	OctreeNode octree[];
};

layout (std430, binding = 1) buffer freelist_ssbo
{
	uint freelist[];
};

layout (std140, binding = 2) readonly uniform octree_depth_ubo
{
	uint octree_depth_bad;
};

uint getPoolIndex(in uint depth, in uvec3 pos);
uint readIndirectionPool(in uint base_location, in uint node_index);
uint readUniformityPool(in uint base_location, in uint node_index);
uint readVoxelTypePool(in uint base_location, in uint node_index);
void insertFreelistVal(in uint index, in bool val);

uint octree_depth;
uint octree_width;
int half_octree_width;

// There will be problems with octree_width values approaching UINT_MAX, but i really
// dont think models that large will be rotated anyway.
// If my math is correct the largest octree width that could posibly work is 2^28, but
// even then im pretty sure the octree pool would be too large to be represented with
// 32-bit unsigned ints.
void main()
{
	octree_width = gl_NumWorkGroups.x * gl_WorkGroupSize.x;
	//octree_width = 1u << octree_depth;
	half_octree_width = int(octree_width >> 1);
	//for (octree_depth = 1u; 1u << octree_depth != octree_width; octree_depth++);
	octree_depth = 1u;
	while (1u << octree_depth != octree_width)
	{
		octree_depth++;
	}

	// calculate pos from instance index
	uvec3 pos = uvec3(gl_GlobalInvocationID);

	// calculate the pool index in the input octree
	uint pool_index = getPoolIndex(octree_depth, pos);	

	// loop through all children and check if they are of the same type
	uint child_pool_index_base = getPoolIndex(octree_depth+1, pos*2);
	uint voxel_type = octree[child_pool_index_base].voxel_type;
	bool can_merge = true;
	for (uint child = 0; child < 8; child++)
	{
		if (octree[child_pool_index_base+child].voxel_type != voxel_type
		    || octree[child_pool_index_base+child].indirection != 0)
		{
			can_merge = false;
			break;
		}
	}
	if (can_merge)
	{
		octree[pool_index].voxel_type = voxel_type;
		octree[pool_index].indirection = 0;
		for (uint child = 0; child < 8; child++)
		{
			insertFreelistVal(child_pool_index_base+child, true);
			//octree[child_pool_index_base+child].voxel_type = 0;
		}
	}
	else
	{
		octree[pool_index].voxel_type = 0; // TODO: LOD?
		octree[pool_index].indirection = child_pool_index_base >> 3;
	}
	insertFreelistVal(pool_index, false);
	
	return;
}


uint getPoolIndex(in uint depth, in uvec3 pos)
{
	uint base_offset = ((1 << (3*(depth-1))) - 1) / 7 * 8;
	uint index = 0u;
	for (int i = 0; i < 10; i++)
	{
		index = bitfieldInsert(index, bitfieldExtract(pos.x, i, 1), i*3, 1);
		index = bitfieldInsert(index, bitfieldExtract(pos.y, i, 1), i*3+1, 1);
		index = bitfieldInsert(index, bitfieldExtract(pos.z, i, 1), i*3+2, 1);
	}
	return base_offset + index;
}


void insertFreelistVal(in uint index, in bool val)
{
/*
	// NOTE: doesn't work because of multithread stuff
	uint bit = (val) ? 1u : 0u;
	uint list_index = index >> 5;
	int bit_offset = 31 - int(index & 31u);
	freelist[list_index] = bitfieldInsert(freelist[list_index], bit, bit_offset, 1);
*/
	uint list_index = index >> 5;
	int bit_offset = 31 - int(index & 31u);
	uint bitfield = bitfieldInsert(0u, 1, bit_offset, 1);
	if (val)
	{
		atomicOr(freelist[list_index], bitfield);
	}
	else
	{
		atomicAnd(freelist[list_index], ~bitfield);
	}
	return;
}
